{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees for Expert Iteration (Reinforcement learning)\n",
    "David Albuja \n",
    "1900863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "28Lr5T-WIxYA"
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K1kr-qL7JD52",
    "outputId": "108ac9ed-e8dd-46ed-af2e-9370334acd44"
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "import random\n",
    "\n",
    "class OXOState:\n",
    "    \"\"\" A state of the game, i.e. the game board.\n",
    "        Squares in the board are in this arrangement\n",
    "        012\n",
    "        345\n",
    "        678\n",
    "        where 0 = empty, 1 = player 1 (X), 2 = player 2 (O)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.playerJustMoved = 2 # At the root pretend the player just moved is p2 - p1 has the first move\n",
    "        self.board = [0,0,0,0,0,0,0,0,0] # 0 = empty, 1 = player 1, 2 = player 2\n",
    "        \n",
    "    def Clone(self):\n",
    "        \"\"\" Create a deep clone of this game state.\n",
    "        \"\"\"\n",
    "        st = OXOState()\n",
    "        st.playerJustMoved = self.playerJustMoved\n",
    "        st.board = self.board[:]\n",
    "        return st\n",
    "\n",
    "    def DoMove(self, move):\n",
    "        \"\"\" Update a state by carrying out the given move.\n",
    "            Must update playerToMove.\n",
    "        \"\"\"\n",
    "        assert move >= 0 and move <= 8 and move == int(move) and self.board[move] == 0\n",
    "        self.playerJustMoved = 3 - self.playerJustMoved\n",
    "        self.board[move] = self.playerJustMoved\n",
    "        \n",
    "    def GetMoves(self):\n",
    "        \"\"\" Get all possible moves from this state.\n",
    "        \"\"\"\n",
    "        return [i for i in range(9) if self.board[i] == 0]\n",
    "    \n",
    "    def GetResult(self, playerjm):\n",
    "        \"\"\" Get the game result from the viewpoint of playerjm. \n",
    "        \"\"\"\n",
    "        for (x,y,z) in [(0,1,2),(3,4,5),(6,7,8),(0,3,6),(1,4,7),(2,5,8),(0,4,8),(2,4,6)]:\n",
    "            if self.board[x] == self.board[y] == self.board[z]:\n",
    "                if self.board[x] == playerjm:\n",
    "                    return 1.0\n",
    "                else:\n",
    "                    return 0.0\n",
    "        if self.GetMoves() == []: \n",
    "            return 0.5 # draw\n",
    "        return False # Should not be possible to get here\n",
    "\n",
    "    def __repr__(self):\n",
    "        s= \"\"\n",
    "        for i in range(9): \n",
    "            s += \".XO\"[self.board[i]]\n",
    "            if i % 3 == 2: s += \"\\n\"\n",
    "        return s\n",
    "\n",
    "class Node:\n",
    "    \"\"\" A node in the game tree. Note wins is always from the viewpoint of playerJustMoved.\n",
    "        Crashes if state not specified.\n",
    "    \"\"\"\n",
    "    def __init__(self, move = None, parent = None, state = None):\n",
    "        self.move = move # the move that got us to this node - \"None\" for the root node\n",
    "        self.parentNode = parent # \"None\" for the root node\n",
    "        self.childNodes = []\n",
    "        self.wins = 0\n",
    "        self.visits = 0\n",
    "        self.untriedMoves = state.GetMoves() # future child nodes\n",
    "        self.playerJustMoved = state.playerJustMoved # the only part of the state that the Node needs later\n",
    "        \n",
    "    def UCTSelectChild(self):\n",
    "        \"\"\" Use the UCB1 formula to select a child node. Often a constant UCTK is applied so we have\n",
    "            lambda c: c.wins/c.visits + UCTK * sqrt(2*log(self.visits)/c.visits to vary the amount of\n",
    "            exploration versus exploitation.\n",
    "        \"\"\"\n",
    "        s = sorted(self.childNodes, key = lambda c: c.wins/c.visits + sqrt(2*log(self.visits)/c.visits))[-1]\n",
    "        return s\n",
    "    \n",
    "    def AddChild(self, m, s):\n",
    "        \"\"\" Remove m from untriedMoves and add a new child node for this move.\n",
    "            Return the added child node\n",
    "        \"\"\"\n",
    "        n = Node(move = m, parent = self, state = s)\n",
    "        self.untriedMoves.remove(m)\n",
    "        self.childNodes.append(n)\n",
    "        return n\n",
    "    \n",
    "    def Update(self, result):\n",
    "        \"\"\" Update this node - one additional visit and result additional wins. result must be from the viewpoint of playerJustmoved.\n",
    "        \"\"\"\n",
    "        self.visits += 1\n",
    "        self.wins += result\n",
    "\n",
    "    def __repr__(self): #Variable added to cehck flow of the varaibles in small iterations\n",
    "        return \"[M:\" + str(self.move) + \" W/V:\" + str(self.wins) + \"/\" + str(self.visits) + \" U:\" + str(self.untriedMoves) + \"P:\" + str(self.playerJustMoved) + \"]\"\n",
    "\n",
    "    def TreeToString(self, indent):\n",
    "        s = self.IndentString(indent) + str(self)\n",
    "        for c in self.childNodes:\n",
    "             s += c.TreeToString(indent+1)\n",
    "        return s\n",
    "\n",
    "    def IndentString(self,indent):\n",
    "        s = \"\\n\"\n",
    "        for i in range (1,indent+1):\n",
    "            s += \"| \"\n",
    "        return s\n",
    "\n",
    "    def ChildrenToString(self):\n",
    "        s = \"\"\n",
    "        for c in self.childNodes:\n",
    "             s += str(c) + \"\\n\"\n",
    "        return s\n",
    "\n",
    "def Exploration_Exploitation (r, dt):\n",
    "    #90% of the choices will be decided by a decsion tree classifier and 10% will be random choices.\n",
    "    #If decision tree choose a position that has already taken, then the decision will be randomly\n",
    "    choices = random.uniform(0.0,1.0) #randomness\n",
    "    \n",
    "    if choices <= 0.9: #90% of decisions taken by decision tree classifer\n",
    "        move = dt.predict([r.board])\n",
    "        move = move[0]\n",
    "        if move not in r.GetMoves(): #if the decision tree chose a move that is already taken, then the decision will be randomly as well\n",
    "            move = random.choice(r.GetMoves())\n",
    "            st_b = list(r.board) \n",
    "            st_b.append(move)\n",
    "            st_tr.append(st_b)\n",
    "    else: #10% of the decision will be taken radomly\n",
    "        move = random.choice(r.GetMoves())  \n",
    "    return move\n",
    "\n",
    "\n",
    "def UCT(start, decisiontree, rootstate, itermax, verbose = False):\n",
    "    \"\"\" Conduct a UCT search for itermax iterations starting from rootstate.\n",
    "        Return the best move from the rootstate.\n",
    "        Assumes 2 alternating players (player 1 starts), with game results in the range [0.0, 1.0].\"\"\"\n",
    "\n",
    "    rootnode = Node(state = rootstate)\n",
    "\n",
    "    for i in range(itermax):\n",
    "        node = rootnode\n",
    "        state = rootstate.Clone()\n",
    "\n",
    "        # Select\n",
    "        while node.untriedMoves == [] and node.childNodes != []: # node is fully expanded and non-terminal\n",
    "            node = node.UCTSelectChild()\n",
    "            state.DoMove(node.move)\n",
    "\n",
    "        # Expand\n",
    "        if node.untriedMoves != []:  # if we can expand (i.e. state/node is non-terminal)\n",
    "            m = random.choice(node.untriedMoves) \n",
    "            state.DoMove(m)\n",
    "            node = node.AddChild(m, state)  # add child and descend tree\n",
    "\n",
    "        # Rollout - this can often be made orders of magnitude quicker using a state.GetRandomMove() function\n",
    "        while state.GetMoves() != []: # while state is non-terminal\n",
    "            if start == 1:\n",
    "                r = random.choice(state.GetMoves())\n",
    "            else:\n",
    "                r = Exploration_Exploitation (state, decisiontree) #Compute the function made it for 90 -10% of decision\n",
    "            state.DoMove(r)\n",
    "\n",
    "        # Backpropagate\n",
    "        while node != None: # backpropagate from the expanded node and work back to the root node\n",
    "            w = state.GetResult(node.playerJustMoved) # state is terminal. Update node with result from POV of node.playerJustMoved\n",
    "            node.Update(w)\n",
    "            \n",
    "            node = node.parentNode\n",
    "\n",
    "    # Output some information about the tree - can be omitted\n",
    "    #if verbose: print(rootnode.TreeToString(0))\n",
    "    #else: print(rootnode.ChildrenToString())\n",
    "    \n",
    "    UCT_value = sorted(rootnode.childNodes, key = lambda c: c.visits)[-1].move # return the move that was most visited\n",
    "    #Most returned best move\n",
    "    #print(\"UCT value:\", UCT_value)\n",
    "    return UCT_value \n",
    "\n",
    "                \n",
    "def UCTPlayGame(start, decisiontree):\n",
    "    \"\"\" Play a sample game between two UCT players where each player gets a different number \n",
    "        of UCT iterations (= simulations = tree nodes).\n",
    "    \"\"\"\n",
    "    state = OXOState()\n",
    "\n",
    "    df_t=[[0,0,0,0,0,0,0,0,0]] #Creating the default row (first row) (code line added)\n",
    "    bm_list=[] # creating a best moves empty list (code line added)\n",
    "    while state.GetMoves() != []:\n",
    "        #print(str(state))\n",
    "        if state.playerJustMoved == 1:\n",
    "            m = UCT(start, decisiontree, rootstate=state, itermax=50, verbose=False)  # play with values for itermax and verbose = True\n",
    "        else:\n",
    "            m = UCT(start, decisiontree, rootstate=state, itermax=50, verbose=False) #itermax decides the total value of visits.\n",
    "        #print(\"Best Move: \" + str(m) + \"\\n\")\n",
    "        state.DoMove(m)\n",
    "        bm_list.append(m) # append the best moves to the list\n",
    "        df_t.append(list(state.board))  #append all the positions list \n",
    "        \n",
    "        if state.GetResult(state.playerJustMoved) != False:\n",
    "            #print(str(state))            \n",
    "            break\n",
    "\n",
    "    if state.GetResult(state.playerJustMoved) == 1.0:\n",
    "        winner = state.playerJustMoved\n",
    "    elif state.GetResult(state.playerJustMoved) == 0.0:\n",
    "        winner = (3-state.playerJustMoved) #Updating player 1\n",
    "    else: \n",
    "        winner=0 #tie\n",
    "\n",
    "    bm_list.append('NaN')  # Append NaN values ti the last state of each game because there are no more moves to choose. (code line added)\n",
    "    \n",
    "    \n",
    "    #Join the postitions board with the correcponding best move\n",
    "    for i in range(len(df_t)): # (code line added)\n",
    "        df_t[i].append(bm_list[i]) # (code line added)\n",
    "    return df_t, winner # (code line added)\n",
    "\n",
    "def dataset (games, start, decisiontree):\n",
    "    \"\"\" Play a single game to the end using UCT for both players. \n",
    "    \"\"\"\n",
    "    #Generate the game for N times (for purpose of the assigment it will be generated 2000 games)\n",
    "    df =[] # LINE ADDED. List of list, each list is a game\n",
    "    fdf = [] # LINE ADDED. List of all the games' stages\n",
    "    \n",
    "    #Creating the counters that will indicate if player 1 or 2 wins, or if the game is tie.\n",
    "    winner1=0\n",
    "    winner2=0\n",
    "    winner0=0\n",
    "    winner=0\n",
    "    \n",
    "    \n",
    "    for i in range(games): # Runing the game for as many times the value in range is written (code line added)\n",
    "        ds, winner = UCTPlayGame(start, decisiontree) # Calling the game to play (code line added)\n",
    "        df.append(ds) # Append the games into a dataframe (code line added)\n",
    "        if winner == 1:\n",
    "            winner1 += 1\n",
    "        elif winner == 2:\n",
    "            winner2 += 1\n",
    "        else:\n",
    "            winner0 += 1\n",
    "    #print (df)\n",
    "\n",
    "    #Change from a list of lists into one list\n",
    "     # (code line added)\n",
    "    for i in df:  # (code line added)\n",
    "        for j in i:  # (code line added)\n",
    "            fdf.append(j)  # (code line added)\n",
    "    #print (fdf)\n",
    "\n",
    "     \n",
    "    #Formating the data frame\n",
    "    data_df=pd.DataFrame(fdf, columns=['pos: 0', 'pos: 1', 'pos: 2', 'pos: 3', 'pos: 4',\n",
    "                                       'pos: 5', 'pos: 6', 'pos: 7', 'pos: 8', 'Best_Move']) #(code line added)\n",
    "    #Deleting the rows that have NaN values  \n",
    "    data_df.drop(data_df[data_df.Best_Move == 'NaN'].index, inplace = True) #(code line added)\n",
    "    #data_df=data_df.ix[data_df.iloc[:,-1]!='NaN'] #(code line added)\n",
    "\n",
    "    #Generate the correct indexing for the rows (because it change after removing NaN values)\n",
    "    data_df.reset_index(drop=True, inplace=True) #(code line added)\n",
    "     \n",
    "    #Printing the final Data Frame\n",
    "    #print(\"wins Player 1:\", winner1 ) # (code line added)\n",
    "    #print(\"wins Player 2:\", winner2 ) # (code line added)\n",
    "    #print(\"None wins:\", winner0 ) # (code line added)\n",
    "    \n",
    "    return data_df # (code line added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the decision tree (The test of the classifiers is in the file named: Training the classifier_Assignment 2.ipynb)\n",
    "\n",
    "def train_DT(input_DT):\n",
    "    features = [\"pos: 0\", \"pos: 1\", \"pos: 2\", \"pos: 3\", \"pos: 4\", \"pos: 5\", \"pos: 6\",\"pos: 7\",\"pos: 8\",]\n",
    "    outcome = [\"Best_Move\"]\n",
    "    #Knowing the features and outcomes of the dataset\n",
    "    X = input_DT[features]\n",
    "    y = input_DT[outcome].astype('int')\n",
    "    #Divide data into training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    # Create Decision Tree classifer object\n",
    "    clf = DecisionTreeClassifier(max_depth=11)\n",
    "    \n",
    "    # Train Decision Tree Classifer\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    # Model Accuracy/recall/precisio train set\n",
    "    #print(classification_report(y_train, y_pred_train))\n",
    "    \n",
    "    # Model Accuracy/recall/precisio test set\n",
    "    #print(classification_report(y_test, y_pred_test))\n",
    "    \n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion that computed that the agent plays with all its past self 10 games and record the results\n",
    "def iterate():\n",
    "    start = 1 #For computing the first iteration (Expert policy)\n",
    "    dc = {} #Dictionary for storing the records\n",
    "    global st_tr\n",
    "    st_tr=[]\n",
    "    decisiontree = None #Storing the classifier\n",
    "    #The range is the number of iterations generated\n",
    "    for i in range (10): \n",
    "        datadf = dataset(300, start, decisiontree) #Playing 300 games for every iterations\n",
    "        game_s = pd.DataFrame(st_tr, columns=['pos: 0', 'pos: 1', 'pos: 2', 'pos: 3', 'pos: 4',\n",
    "                                       'pos: 5', 'pos: 6', 'pos: 7', 'pos: 8', 'Best_Move'])\n",
    "        #Create the final dataset which is going to be computed in the classifer\n",
    "        datadf = pd.concat([datadf,game_s], ignore_index=True, axis=0)\n",
    "        decisiontree = train_DT(datadf)\n",
    "        dc.update({i:decisiontree})\n",
    "        start = 0\n",
    "        st_tr.clear()\n",
    "    return dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modification of the main functions of the code provided for unification of the previous funtions.\n",
    "\n",
    "def mo_UCT(DT_player1, DT_player2,rootstate, itermax, verbose = False): \n",
    "    \"\"\" Conduct a UCT search for itermax iterations starting from rootstate.\n",
    "        Return the best move from the rootstate.\n",
    "        Assumes 2 alternating players (player 1 starts), with game results in the range [0.0, 1.0].\"\"\"\n",
    "\n",
    "    rootnode = Node(state = rootstate)\n",
    "\n",
    "    for i in range(itermax):\n",
    "        node = rootnode\n",
    "        state = rootstate.Clone()\n",
    "\n",
    "         # Select\n",
    "        while node.untriedMoves == [] and node.childNodes != []: # node is fully expanded and non-terminal\n",
    "            node = node.UCTSelectChild()\n",
    "            state.DoMove(node.move)\n",
    "\n",
    "        # Expand\n",
    "        if node.untriedMoves != []:  # if we can expand (i.e. state/node is non-terminal)\n",
    "            m = random.choice(node.untriedMoves) \n",
    "            state.DoMove(m)\n",
    "            node = node.AddChild(m, state)  # add child and descend tree\n",
    "\n",
    "        # Rollout - this can often be made orders of magnitude quicker using a state.GetRandomMove() function\n",
    "        while state.GetMoves() != []: # while state is non-terminal\n",
    "            \n",
    "            if(state.playerJustMoved==1):\n",
    "                r=DT_player1.predict([state.board])\n",
    "                r=r[0]\n",
    "                if r not in state.GetMoves():\n",
    "                    r=random.choice(state.GetMoves())\n",
    "            else:\n",
    "                r=DT_player2.predict([state.board])\n",
    "                r=r[0]\n",
    "                if r not in state.GetMoves():\n",
    "                    r=random.choice(state.GetMoves())\n",
    "            state.DoMove(r)\n",
    "\n",
    "        # Backpropagate\n",
    "        while node != None: # backpropagate from the expanded node and work back to the root node\n",
    "            node.Update(state.GetResult(node.playerJustMoved)) # state is terminal. Update node with result from POV of node.playerJustMoved\n",
    "            node = node.parentNode\n",
    "\n",
    "    # Output some information about the tree - can be omitted\n",
    "    #if (verbose): print(rootnode.TreeToString(0))\n",
    "    #else: print(rootnode.ChildrenToString())\n",
    "\n",
    "    return sorted(rootnode.childNodes, key = lambda c: c.visits)[-1].move # return the move that was most visited\n",
    "                \n",
    "def mo_UCTPlayGame(DT_player1, DT_player2):\n",
    "    \"\"\" Play a sample game between two UCT players where each player gets a different number \n",
    "        of UCT iterations (= simulations = tree nodes).\n",
    "    \"\"\"\n",
    "    \n",
    "    state = OXOState() \n",
    "    \n",
    "    while (state.GetMoves() != []):\n",
    "        if state.playerJustMoved == 1:\n",
    "            m = mo_UCT(DT_player1, DT_player2,rootstate = state, itermax = 50, verbose = False) # play with values for itermax and verbose = True\n",
    "        else:\n",
    "            m = mo_UCT(DT_player1, DT_player2, rootstate = state, itermax = 50, verbose = False) #Giving more probability of winnign to player 1\n",
    "        #print(\"Best Move: \" + str(m) + \"\\n\")\n",
    "        state.DoMove(m)\n",
    "        if state.GetResult(state.playerJustMoved) != False:\n",
    "            break\n",
    "    if state.GetResult(state.playerJustMoved) == 1.0:\n",
    "        return state.playerJustMoved\n",
    "    elif state.GetResult(state.playerJustMoved) == 0.0:\n",
    "        return (3-state.playerJustMoved)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for running the complete system (Imitation learning)\n",
    "def Imitation_Learning(games):\n",
    "    for i in range(games):\n",
    "        call=iterate() #Calling the function that that computed that the agent plays with all its past self 10 games and record the results\n",
    "        clf_10=0 #Counter of the 10th decision tree of every iteration\n",
    "        clf_dif=0 # Counter of all decision trees but 10th for every iteration\n",
    "        tie=0 #Counter of games ending in tie\n",
    "        #Compute for the 9 postions\n",
    "        for i in range(len(call)-1):\n",
    "            w = mo_UCTPlayGame(call[len(call)-1], call[i])\n",
    "            if w==1:\n",
    "                clf_10+=1\n",
    "            elif w==2:\n",
    "                clf_dif+=1\n",
    "            else:\n",
    "                tie+=1\n",
    "        #Printing the outputs\n",
    "        print(\"10th DT Winnings  \", clf_10)\n",
    "        print(\"Other DTs Winnings: \", clf_dif)\n",
    "        print(\"Ties : \", tie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th DT Winnings   5\n",
      "Other DTs Winnings:  0\n",
      "Ties :  4\n",
      "10th DT Winnings   6\n",
      "Other DTs Winnings:  0\n",
      "Ties :  3\n",
      "10th DT Winnings   6\n",
      "Other DTs Winnings:  0\n",
      "Ties :  3\n",
      "10th DT Winnings   2\n",
      "Other DTs Winnings:  1\n",
      "Ties :  6\n",
      "10th DT Winnings   7\n",
      "Other DTs Winnings:  0\n",
      "Ties :  2\n",
      "10th DT Winnings   6\n",
      "Other DTs Winnings:  0\n",
      "Ties :  3\n",
      "10th DT Winnings   5\n",
      "Other DTs Winnings:  1\n",
      "Ties :  3\n",
      "10th DT Winnings   5\n",
      "Other DTs Winnings:  1\n",
      "Ties :  3\n",
      "10th DT Winnings   6\n",
      "Other DTs Winnings:  0\n",
      "Ties :  3\n",
      "10th DT Winnings   7\n",
      "Other DTs Winnings:  1\n",
      "Ties :  1\n"
     ]
    }
   ],
   "source": [
    "#Executing the function of imitation learning\n",
    "Imitation_Learning(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning is improving based on the greater number of winnings for the 10th classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assigment 1 DS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
